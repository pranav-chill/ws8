 1002  cd CUSTOMERS
 1003  ls
 1004  rm corr_customers
 1005  mv cust100.txt
 1006  mv cust100.txt datamash-1.3
 1007  cd datamash-1.3
 1008  for id in $(cat cust100.txt); o corr=`~/datamash-1.3/datamash -W ppearson 1:2 < $f`; id=$(echo $f | cut -d '.' -f1); echo "$id      $corr" >>corr_customers; done   
 1009  for id in $(cat cust100.txt); do corr=`~/datamash-1.3/datamash -W ppearson 1:2 < $f`; id=$(echo $f | cut -d '.' -f1); echo "$id      $corr" >>corr_customers; done
 1010  for id in $(cat cust100.txt); do  datamash-1.3/datamash -W ppearson 1:2 < CUSTOMERS/${id}.txt; done > customercorrval.tmp
 1011  cd ~/CUSTOMERS
 1012  cd
 1013  cd a2
 1014  cd CUSTOMERS
 1015  for f in *.txt; do corr=`~/datamash-1.3/datamash -W ppearson 1:2 < $f`; id=$(echo $f | cut -d '.' -f1); echo "$id      $corr" >>corr_customers; done      
 1016  ls
 1017  cd datamash-1.3
 1018  ls
 1019  mv cust100.txt CUSTOMERS
 1020  cd
 1021  cd a1
 1022  cd
 1023  cd a2
 1024  cd CUSTOMERS
 1025  for id in $(cat cust100.txt); do datamash-1.3/datamash -W ppearson 1:2 < CUSTOMERS/${id}.txt; done > customer-correlation-values.tmp
 1026  ls
 1027  rm corr_customers
 1028  rm customer-correlation-values.tmp
 1029  for f in *.txt; do corr=`~/datamash-1.3/datamash -W ppearson 1:2 < $f`; id=$(echo $f | cut -d '.' -f1); echo "$id      $corr" >>corr_customers; done      
 1030  cd ~/a2
 1031  ls
 1032  nano cust_n100.txt
 1033  tr -s " " "\t" < cust100.tmp | cut -f 3 > cust100.txt
 1034  ls
 1035  nano cust100.txt
 1036  for id in $(cat cust100.txt); do?
 1037  for id in $(cat cust100.txt); do datamash-1.3/datamash -W ppearson 1:2 < CUSTOMERS/${id}.txt; done > custcorrval.tmp
 1038  cd CUSTOMERS
 1039  ls
 1040  CP CUSTOMERS datamash-1.3
 1041  cp CUSTOMERS datamash-1.3
 1042  cp -a CUSTOMERS datamash-1.3
 1043  cp -a /CUSTOMERS/. /datamash-1.3/
 1044  ~/datamash-1.3$ for file in *.txt; do ./datamash  -W ppearson 1:2 < $file; done 
 1045  cd datamash-1.3
 1046  for file in $HOME/a2/CUSTOMERS/*.txt; do ./datamash  -W ppearson 1:2 < $file; done 
 1047  for file in $HOME/a2/PRODUCTS*.txt; do ./datamash  -W ppearson 1:2 < $file; done
 1048  cd
 1049  cd a2
 1050  ls
 1051  cd 
 1052  cd a2
 1053  cd PRODUCTS
 1054  ls
 1055  # install datamash
 1056  wget http://ftp.gnu.org/gnu/datamash/datamash-1.3.tar.gz
 1057  tar -xzf datamash-1.3.tar.gz
 1058  cd datamash-1.3/
 1059  ./configure
 1060  make
 1061  for file in $HOME/a2/PRODUCTS*.txt; do ./datamash  -W ppearson 1:2 < $file; done
 1062  for file in $HOME/a2/PRODUCTS/*.txt; do ./datamash  -W ppearson 1:2 < $file; done
 1063  cd
 1064  cd a2
 1065  cd CUSTOMERS
 1066  cd datamash-1.3
 1067  for file in $HOME/a2/CUSTOMERS/*.txt; do ./datamash  -W mean 2 < $file; done 
 1068  cd
 1069  cd a2
 1070  cd PRODUCTS
 1071  cd datamash-1.3
 1072  for file in $HOME/a2/PRODUCTS*.txt; do ./datamash  -W mean 2 < $file; done 
 1073  for file in $HOME/a2/PRODUCTS/*.txt; do ./datamash  -W mean 2 < $file; done 
 1074  for file in $HOME/a2/PRODUCTS/*.txt;do ./datamash  -W mean 2 < $file; done | sort -n | tail -1
 1075  for file in $HOME/a2/PRODUCTS/*.txt; do ./datamash  -W mean 2 < $file; done | sort -n | tail -1
 1076  for file in $HOME/a2/PRODUCTS/*.txt; do ./datamash  -W mean 2 < $file; done | sort -n | head -1
 1077  alias l="ls -latr"
 1078  rm a2.txt
 1079  rm -r a2
 1080  ;s
 1081  ls
 1082  script a2.txt
 1083  less a2.txt
 1084  sudo gedit a2.txt
 1085  vi a2.txt
 1086  nano a2.txt
 1087  sudo gedit a2.txt
 1088  nano a2.txt
 1089  alias l="ls -latr"
 1090  nano a2.txt
 1091  alias l="ls -latr"
 1092  script test
 1093  less test.txt
 1094  ls
 1095  nano test
 1096  nano a2.txt
 1097  git init
 1098  git status
 1099  git commit -m "assignment 2"
 1100  git add a2.txt
 1101  git status
 1102  git remote add origin https://github.com/pranav-chill/a2.git
 1103  git push -u origin master
 1104  git status
 1105  git init
 1106  git status
 1107  git commit -m "Assignment 2"
 1108  git remote add origin https://github.com/pranav-chill/a2.git
 1109  git remote remove origin
 1110  git remote add origin https://github.com/pranav-chill/a2.git
 1111  git push -u origin master
 1112  git pull origin master
 1113  git rm README.txt
 1114  git checkout master
 1115  git rm -r README.txt
 1116  git ls
 1117  git a2 ls
 1118  cd
 1119  ls
 1120  cd a2
 1121  ls
 1122  cd PRODUCTS
 1123  ls
 1124  cd
 1125  mkdir as6
 1126  cd as6
 1127  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1128  echo $DATETIME
 1129  cd
 1130  cp 0345451120.txt
 1131  cp 0345451120.txt 0345451120.txt.test.$DATETIME
 1132  cd cp 0345451120.txt 0345451120.txt.test.$DATETIME
 1133  ls
 1134  mkdir ws8
 1135  mkdir ws6
 1136  cd mkdir ~/ws6/PRODUCTS
 1137  mkdir ~/ws6/PRODUCTS
 1138  grep -i 0345451120 amazon_reviews_us_Books_v1_02.tsv >> ~/ws6/PRODUCTS/0345451120.txt
 1139  head wc -l~/ws6/PRODUCTS/0451527100.txt
 1140  head wc -l ~/ws6/PRODUCTS/0345451120.txt
 1141  head wc ~/ws6/PRODUCTS/0345451120.txt
 1142  cd ws6
 1143  ls
 1144  cd PRODUCTS
 1145  ls
 1146  grep -i 0345451120 amazon_reviews_us_Books_v1_02.tsv >> ~/ws6/PRODUCTS/0345451120.txt
 1147  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1148  echo $DATETIME
 1149  d ~/ws6/PRODUCTS
 1150  cd ~/ws6/PRODUCTS
 1151  cp 0345451120.txt 0345451120.$DATETIME.txt
 1152  echo "marketplace customer_id review_id product_id product_parent product_title product_category 5 7 10 N N headline body 2021" >> 0345451120.txt
 1153  tail -n 1 0345451120.20211014_052345.txt
 1154  ls
 1155  tail -n 1 0345451120.20211014_054029.txt
 1156  ln -s 0345451120.txt.test.20211014_054029 0345451120.txt.test.LATEST
 1157  ls
 1158  exit
 1159  cd
 1160  ls
 1161  cd ws6
 1162  ls
 1163  cd PRODUCTS
 1164  LS
 1165  PS
 1166  ls
 1167  export DATETIME=`date "+%Y%m%d_%H%M%S"`
 1168  echo $DATETIME
 1169  cp 0345451120.txt 0345451120.$DATETIME.txt
 1170  echo "marketplace customer_id review_id product_id product_parent product_title product_category 5 7 10 N N headline body 2021" >> 0345451120.txt
 1171  ls
 1172  tail -n 1 0345451120.20211014_052345.txt
 1173  ls
 1174  rm 0345451120.txt
 1175  rm 0345451120.20211014_052345.txt
 1176  ls
 1177  cd
 1178  script ws6.txt
 1179  cd ~/ws6/PRODUCTS
 1180  ls
 1181  head -n 0345451120.txt.test.LATEST
 1182  crontab -e
 1183  ls
 1184  vi crontab file
 1185  cd ~/ws6/PRODUCTS
 1186  ls
 1187  cd
 1188  ls
 1189  nano ws6.txt
 1190  cd ~/ws6/PRODUCTS
 1191  ls
 1192  rm 0345451120.txt.test.LATEST
 1193  rm 0345451120.20211014_054029.txt
 1194  script ws6.txt
 1195  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1196  echo $DATETIME
 1197  cp 0345451120.txt 0345451120.$DATETIME.txt
 1198  ls
 1199  echo "5  5" >> 0345451120.20211014_060817.txt
 1200  ln -s 0345451120.20211014_060817.txt 0345451120.20211014_060817.txt.test.
 1201  ls
 1202  rm 0345451120.20211014_060817.txt.test.
 1203  ln -s 0345451120.txt.test.20211014_060817 0345451120.LATEST.txt
 1204  ls
 1205  crontab cronfile
 1206  crontab -l
 1207  cd ws6
 1208  cd PRODUCTS
 1209  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1210  echo $DATETIME
 1211  cp 0345451120.txt 0345451120.$DATETIME.txt
 1212  ls
 1213  echo "5 5" >> 0345451120.20211015_014033.txt
 1214  ln -s 0345451120.txt.test.20211015_014033 0345451120.LATEST.txt
 1215  ls
 1216  cd
 1217  vi crontab1
 1218  cat cronfile1
 1219  vi cronfile`
 1220  ;
 1221  q
 1222  vi cronfile1
 1223  cat cronfile1
 1224  cat cronfile1  * * * * * sum=$(cut -f 8 ~/ws6/PRODUCTS/0345451120.LATEST.txt | paste -sd + | bc); count=$(wc -l < ~/ws6/PRODUCTS/0345451120.LATEST.txt); echo "scale=2; $sum/$count" | bc > ~/ws6/PRODUCTS/0345451120.LATEST.txt -----
 1225  ls
 1226  cd ~/ws6/PRODUCTS
 1227  ls
 1228  vi 0345451120.LATEST.tx
 1229  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1230  echo $DATETIME
 1231  cp 0345451120.txt 0345451120.20211015_015827.txt
 1232  ls
 1233  rm ws6.txt
 1234  cd ws6
 1235  ls
 1236  cd PRODUCTS
 1237  ls
 1238  rm 0345451120.LATEST.txt
 1239  rm 0345451120.20211014_060817.txt
 1240  cd
 1241  script ws6.txt
 1242  rm ws6.txt
 1243  cd ~/ws6/PRODUCTS
 1244  rm 0345451120.LATEST.txt 
 1245  rm 0345451120.20211015_014033.txt
 1246  cd
 1247  script ws6.txt
 1248  rm ws6.txt
 1249  script ws6.txt
 1250  cd ~/ws6/PRODUCTS
 1251  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1252  echo $DATETIME
 1253  cp 0345451120.txt 0345451120.20211015_015938
 1254  DATETIME=$(date "+%Y%m%d_%H%M%S")
 1255  echo $DATETIME
 1256  cp 0345451120.txt 0345451120.$DATETIME.txt
 1257  ls
 1258  echo "5  5" >> 0345451120.20211015_053058.txt
 1259  ln -s 0345451120.txt.test.20211015_053058 0345451120.LATEST.txt
 1260  l
 1261  ls
 1262  vi crontab1
 1263  cat cronfile * * * * * awk '{ sum += $8 } END { if (NR > 0) print sum / NR }' ~/ws6/PRODUCTS/0345451120.LATEST.txt > ~/ws6/PRODUCTS/0345451120.AVERAGE.txt 2>&1
 1264  ls
 1265  cs ~/ws6/PRODUCTS
 1266  cd ~/ws6/PRODUCTS
 1267  ls
 1268  rm 0345451120.20211015_015938
 1269  rm ws6.txt
 1270  ls
 1271  script ws6.txt
 1272  cmds.log
 1273  commands
 1274  history
 1275  history > cmds.log
 1276  ls
 1277  nano ws6.txt
 1278  git init
 1279  git status
 1280  git add cmds.log
 1281  git add ws6.txt
 1282  git status
 1283  git commit -m "Worksheet 6"
 1284  git remote add origin https://github.com/pranav-chill/ws6.git
 1285  git push -u origin master
 1286  git remote add origin https://github.com/pranav-chill/ws6.git
 1287  git push -u origin master
 1288  git pull origin master
 1289  sed -i 's/[,.;]//g' 0345451120.txt
 1290  sed -i 's/and//g' 0345451120.txt
 1291  sed -i 's/if//g' 0345451120.txt
 1292  sed -i 's/<[a-zA-Z]* \/>//g' 0345451120.txt
 1293  less 0345451120.txt
 1294  cut -f 14 0345451120.txt > ws7.output.txt
 1295  cd ws6
 1296  cd PRODUCTS
 1297  ;s
 1298  ls
 1299  cd
 1300  ls
 1301  mkdir ws7
 1302  cd ws7
 1303  mkdir PRODUCTS
 1304  cd
 1305  grep -i 0345451120 >> ~/ws7/PRODUCTS/0345451120.txt
 1306  cd ~/ws7/PRODUCTS
 1307  ls
 1308  nano 0345451120.txt
 1309  cd
 1310  cd ~/ws7/PRODUCTS
 1311  rm 0345451129.txt
 1312  ls
 1313  rm 0345451120.txt
 1314  d
 1315  cd
 1316  grep -i 0345451120 amazon_reviews_us_Books_v1_02.tsv >> ~/ws7/PRODUCTS/0345451120.txt
 1317  cd ~/ws7/PRODUCTS
 1318  ls
 1319  nano 0345451120.txt
 1320  script ws7.txt
 1321  nano ws7.txt
 1322  history > cmds.log
 1323  ls
 1324  git status
 1325  git add ws7.txt
 1326  git add cmds.log
 1327  git status
 1328  git commit -m "Worksheet 7"
 1329  git remote add origin https://github.com/pranav-chill/ws7.git
 1330  git push -u origin master
 1331  git remote add origin https://github.com/pranav-chill/ws7.git
 1332  git remote remove origin https://github.com/pranav-chill/ws7.git
 1333  git remote add origin https://github.com/pranav-chill/ws7.git
 1334  git remote rm origin
 1335  git remote add origin https://github.com/pranav-chill/ws7.git
 1336  cd
 1337  cd q2
 1338  cd a2
 1339  ls
 1340  cd CUSTOMERS
 1341  ls
 1342  cd
 1343  mkdir a3
 1344  cd a4
 1345  cd a3
 1346  mkdir PRODUCTS
 1347  mkdir CUSTOMERS
 1348  cd
 1349  cd ~/a2/CUSTOMERS
 1350  cd
 1351  cp ~/a2/CUSTOMERS ~/a3/CUSTOMERS
 1352  cp /home/pranav/a2/CUSTOMERS /home/pranav/a3/CUSTOMERS
 1353  cp -r /home/pranav/a2/CUSTOMERS /home/pranav/a3/CUSTOMERS
 1354  cd ~/a3/CUSTOMERS
 1355  ls
 1356  CUSTOMERS
 1357  cd CUSTOMERS
 1358  ls
 1359  cp -r /home/pranav/a2/CUSTOMERS /home/pranav/a3
 1360  cd
 1361  cd /home/pranav/a3
 1362  ls
 1363  ls CUSTOMERS
 1364  ls PRODUCTS
 1365  cd PRODUCTS
 1366  ls
 1367  cd
 1368  ~/a3
 1369  cd a3
 1370  ls
 1371  rm -r CUSTOMERS
 1372  rm -r PRODUCTS
 1373  ls
 1374  cs 
 1375  cd
 1376  cp -r /home/pranav/a2 /home/pranav/a3
 1377  cd a3
 1378  ls
 1379  cd a2
 1380  ls
 1381  cd
 1382  cd a2
 1383  ls
 1384  cd CUSTOMERS
 1385  ls
 1386  cd
 1387  cd a3
 1388  rm -r a2
 1389  cp -r /home/pranav/a2/CUSTOMERS /home/pranav/a3
 1390  ls
 1391  ls CUSTOMERS
 1392  cp -r /home/pranav/a2/PRODUCTS /home/pranav/a3
 1393  ls
 1394  cd PRODUCTS
 1395  ls
 1396  cd
 1397  for FILE in CUSTOMERS/*.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > CUSTOMERS/$(basename $FILE .txt).BINARY.txt; done
 1398  or FILE in PRODUCTS/*.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > PRODUCTS/$(basename $FILE .txt).BINARY.txt; done
 1399  for FILE in PRODUCTS/*.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > PRODUCTS/$(basename $FILE .txt).BINARY.txt; done
 1400  for FILE in CUSTOMERS/*.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> a3top100norm.txt ; done
 1401  ls
 1402  cd CUSTOMERS
 1403  ls
 1404  for FILE in CUSTOMERS/*.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> a3top100norm.txt ; done
 1405  for FILE in *.BINARY.txt ; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> a3top100norm.txt ; done
 1406  cd ~/a3/PRODUCTS
 1407  ls
 1408  for FILE in *.BINARY.txt ; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> a3top100normproducts.txt ; done
 1409  ls
 1410  nano a3top100normproducts.txt
 1411  cd
 1412  cd a3
 1413  ls
 1414  ls FILE in CUSTOMERS
 1415  for FILE in CUSTOMERS/*.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> tezt.txt ; doneM ;
 1416  for FILE in CUSTOMERS/*.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> tezt.txt; done
 1417  vi  12670864.txt
 1418  script a3.txt
 1419  ls
 1420  cd
 1421  rm -r a3
 1422  ls
 1423  for FILE in ~/a3/CUSTOMERS ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;`; if [ ! -z "$customerID" ]; then grep $customerID amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/a3/CUSTOMERS/$customerID.TOTAL.txt; echo "customerID: $customerID, count: $count"; ((count ++)); fi; done
 1424  ssh 12.42.205.101
 1425  cd a2
 1426  cd
 1427  mkdir a3
 1428  cp ~/a2/CUSOMTERs a3
 1429  cp ~/a2/CUSOMTERS a3
 1430  cd a3
 1431  ls
 1432  cd
 1433  cd a1
 1434  cd
 1435  cd a2
 1436  ls
 1437  cd
 1438  cp ~/a2/CUSTOMERS a3
 1439  cp -r ~/a2/CUSTOMERS a3
 1440  cd a3
 1441  ls
 1442  cd CUSTOMERS
 1443  ls
 1444  cd
 1445  cp -r ~/a2/PRODUCTS a3
 1446  cd ~/a3/PRODUCTS
 1447  ls
 1448  rm B000B5RXSG.txt
 1449  cd
 1450  ls
 1451  script a3.txt
 1452  rm a3.txt
 1453  cd ~/a3/CUSTOMERS
 1454  for FILE in *.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > /$(basename $FILE .txt).BINARY.txt; done
 1455  ls
 1456  for FILE in ~/a3/CUSTOMERS/*.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > ~/a3/CUSTOMERS/$(basename $FILE .txt).BINARY.txt; done
 1457  for FILE in ~/a3/PRODUCTS/*.txt;  do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > ~/a3/PRODUCTS/$(basename $FILE .txt).BINARY.txt; done
 1458  for FILE in ~/a3/CUSTOMERS/*.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> top100customersnorm.txt ; done
 1459  cd ~/a3/CUSTOMERS
 1460  for FILE in *.BINARY.txt; do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> top100customersnorm.txt ; done
 1461  cd ~/a3/PRODUCTS
 1462  LS
 1463  ls
 1464  for FILE in *.BINARY.txt;  do corr=$(./datamash-1.3/datamash -W ppearson 1:2 < $FILE); printf "%s\t%s\n" "$(basename $FILE)" "$corr" >> top100prodnorm.txt; done
 1465  sort -k 2 -n -r top100prodnorm.txt | head -n 1
 1466  cd a3
 1467  ls
 1468  ls CUSTOMERS
 1469  cd
 1470  for FILE in CUSTOMERS-A3/*.txt; do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > CUSTOMERS-A3/$(basename $FILE .txt).BINARY.txt; done
 1471  script a3.txt
 1472  ls
 1473  rm a3.txt
 1474  rm -r a3
 1475  for file in `ls ~/a3/CUSTOMERS' ;  do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/a3/CUSTOMERS/$customerID.TOTAL.txt; echo "customerID: $customerID, count: $count"; ((count ++)); fi; done
 1476  cd a2
 1477  cd CUSTOMERS
 1478  ls 
 1479  vi 12080245.txt
 1480  vi vi 12080245.txt
 1481  vi 31821274.txt  
 1482  cd
 1483  for file in `ls ~/a2/CUSTOMERS' ; do customerID=`echo $file | sed -e 's/\.txt//;/.TOTAL/d;/.BINARY/d;`; if [ ! -z "$customerID" ]; then grep $customerID ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 8-10 | awk -F '\t' '{if ($3 != 0) print $2, $1, $3, $2/$3; else print $2, $1, $3, $3 }' OFS='\t' > ~/a2/CUSTOMERS/$customerID.TOTAL.txt; echo "customerID: $customerID, count: $count"; ((count ++)); fi; done
 1484  for FILE in ~/a3/CUSTOMERS*.txt do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > ~/a3/CUSTOMERS/$(basename $FILE .txt).BINARY.txt; done
 1485  for FILE in ~/a3/CUSTOMERS/*.txt  do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > ~/a3/CUSTOMERS/$(basename $FILE .txt).BINARY.txt; done
 1486  cd ~/a3/CUSTOMERS
 1487  for FILE in ~/a2/CUSTOMERS/*.txt  do median=$(awk '{if ($3>0){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}}' < $FILE | sort -k 2 -n | awk '{a[i++]=$2;} END {print a[int(i/2)];}'); awk -v median=$median '{if ($3>0){ if ($2/$3 > median){printf "%s\t%s\n",$1,$2/$3} else {printf "%s\t0\n",$1}} else {printf "%s\t0\n",$1}}' < $FILE > ~/a2/CUSTOMERS/$(basename $FILE .txt).BINARY.txt; done
 1488  cd a3
 1489  cd CUSTOMERS
 1490  for f in *.txt; do awk -v OFS='   ' '{$4 = ($3 != 0) ? sprintf("%.3f", $2 / $3) : "0"}1' $f | sort -n -k 4 > $f.sorted.txt ; done
 1491  for f in *.sorted.txt; do id=$(echo $f | cut -d '.' -f1); median=$(grep $f medians.txt | cut -d ' ' -f2) ; awk -v median=$median '{$2 = ($4 >=  median) ? "1" : "0"}1' $f >> $id.BINARY.txt ; done
 1492  ls
 1493  nano 12080245.BINARY.txt      16121903.txt.sorted.txt  34209528.txt             37369285.BINARY.txt      44731853.txt.sorted.txt  48139995.txt             50455329.BINARY.txt      51380442.txt.sorted.txt
 1494  vi 34407806.BINARY.txt 
 1495  cd
 1496  ls
 1497  cd a2
 1498  CUSTOMERS
 1499  cd CUSTOMERS
 1500  ls
 1501  cd
 1502  mkdir a3
 1503  cd a3
 1504  mkdir CUSTOMERS
 1505  mkdir PRODUCTS
 1506  cd
 1507  cd a3
 1508  cp ../a2/CUSTOMERS ../a3/CUSTOMERS
 1509  cp -r ../a2/CUSTOMERS ../a3/CUSTOMERS
 1510  cd CUSTOMERS
 1511  ls
 1512  ~ /a3
 1513  cd ~/a3
 1514  rm -r CUSTOMERS
 1515  ls
 1516  cp -r ~/a2/CUSTOMERS 
 1517  cp -r ~/a2/CUSTOMERS a3
 1518  ls
 1519  cd a3
 1520  ls
 1521  cd ~/a3
 1522  rm -r a3
 1523  ls
 1524  rm -r PRODUCTS
 1525  cd
 1526  cp -r ~/a2/CUSOMTERS ~/a3
 1527  ls
 1528  cp -r ~/a2/CUSTOMERS ~/a3/
 1529  cd a3
 1530  ls
 1531  cd CUSTOMERS
 1532  ls
 1533  cd
 1534  cp -r ~/a2/PRODUCTS ~/a3/
 1535  cd a4
 1536  cd a3
 1537  ls
 1538  cd PRODUCTS
 1539  ls
 1540  rm B000B5RXSG.txt
 1541  cd
 1542  script a3.txt
 1543  cd
 1544  ls
 1545  rm a3.txt
 1546  cd a3
 1547  rm -r CUSTOMERS
 1548  rm -r PRODUCTS
 1549  cd a2
 1550  cd ~/a2
 1551  l
 1552  ls
 1553  nano cust_n100
 1554  vi prod100.tx
 1555  vi prod100.txt
 1556  mkdir a3
 1557  ls
 1558  cd a3
 1559  ls
 1560  cd
 1561  mkdir ~/a3/CUSTOMERS
 1562  for file in ~/a2/CUSTOMERS/*.txt; do median=`sort -n -k 2 $file | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median 'BEGIN {OFS=FS} $2 < median {print $1,0} $2 >= median {print $1,1}' $file; ;
 1563  for file in ~/a2/CUSTOMERS/*.txt; do id="$(basename "$file" | sed 's/\(.*\)\..*/\1/')"; median=`sort -nk2 $file | awk '{ a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $file > ~/a3/CUSTOMERS/$id.BINARY.txt; done
 1564  cd a3
 1565  cd CUSTOMERS
 1566  ls
 1567  head 23488951.BINARY.txt
 1568  cd datamash-1.3/
 1569  cd
 1570  cd datamash-1.3/
 1571  head 40824697.BINARY.txt
 1572  cd ~/a3/CUSTOMERS
 1573  head 45405508.BINARY.txt
 1574  head 51814959.BINARY.txt
 1575  head 12080245.BINARY.txt
 1576  head 53072811.BINARY.txt
 1577  head 49718706.BINARY.txt
 1578  head 46619300.BINARY.txt 
 1579  cd ~/a2/CUSTOMERS
 1580  ls
 1581  cd datamash-1.3
 1582  for file in ~/a3/CUSTOMERS/*.txt; do do id="$(basename "$file" | sed 's/\(.*\)\..*/\1/')"; CORR=`./datamash  -W ppearson 1:2 < $file`; echo "$id $CORR" >> ~/a3/custcorrelation
 1583  for file in ~/a3/CUSTOMERS/*.txt; do id="$(basename "$file" | sed 's/\(.*\)\..*/\1/')"; CORR=`./datamash  -W ppearson 1:2 < $file`; echo "$id $CORR" >> ~/a3/custcorrelation; done
 1584  cd
 1585  cd a3
 1586  ls
 1587  head custcorrelation
 1588  ls
 1589  rm custcorrelation
 1590  ls
 1591  cd CUSTOMERS
 1592  ls
 1593  cd
 1594  cd a3
 1595  rm -r CUSTOMERS
 1596  cd
 1597  mv ~/a2/CUSTOMERS ~/a3/
 1598  cd a3
 1599  ls
 1600  CUSTOMERS
 1601  ls
 1602  cd CUSTOMERS
 1603  ls
 1604  cd
 1605  cd ~/a3/CUSTOMERS
 1606  for i in {1..200}; do filename=$(ls | head -n $i | tail -1) && filename2=$(echo $filename | cut -f 1 -d '.') && median=$(awk '{ sum+=$2; n++} END {print sum/n;}' $filename) &&  awk -v average="$median" '{if($2>average) print $1, "\t", 1; else print $1, "\t", 0}' $filename > $filename2.BINARY.txt;  done
 1607  ls
 1608  head 12080245.BINARY.txt
 1609  cd
 1610  cd a3
 1611  rm -r PRODUCTS
 1612  cd
 1613  mv ~/a2/PRODUCTS ~/a3/
 1614  cd a3
 1615  ls
 1616  cd PRODUCTS
 1617  for i in {1..200}; do filename=$(ls | head -n $i | tail -1) && filename2=$(echo $filename | cut -f 1 -d '.') && median=$(awk '{ sum+=$2; n++} END {print sum/n;}' $filename) &&  awk -v average="$median" '{if($2>average) print $1, "\t", 1; else print $1, "\t", 0}' $filename > $filename2.BINARY.txt;  done
 1618  ls
 1619  head 0060283262.BINARY.txt
 1620  ls
 1621  vi B000B5RXSG.txt
 1622  head B000B5RXSG.BINARY.txt
 1623  ls
 1624  cd ~/datamash-1.3/
 1625  cd datamash-1.3
 1626  or i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/100custcorr.txt; done
 1627  for i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/100custcorr.txt; done
 1628  cd ~/a3/CUSTOMERS
 1629  ls
 1630  head 100custcorr.txt
 1631  tail 100custcorr.txt  
 1632  less 100custcorr.txt  
 1633  nano 100custcorr.txt  
 1634  ls
 1635  cd datamash-1.3
 1636  for i in {1..100}; do filename=$(ls ~/a3/PRODUCTS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/PRODUCTS/$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/PRODUCTS/100prodcorr.txt; done
 1637  cd ~/a3/PRODUCTS
 1638  ls
 1639  less 100prodcorr.txt 
 1640  cd ~/a3/CUSTOMERS
 1641  ls
 1642  sort -k 2 -r 100custcorr.txt > sortedcust_corr.txt
 1643  head sortedcust_corr.txt
 1644  nano sortedcust_corr.txt
 1645  vi sortedcust_corr.txt
 1646  grep -Ev 'nan' sortedcust_corr.txt > newone.txt
 1647  nano newone.txt
 1648  cd ~/a3/PRODUCTS
 1649  ls
 1650  grep -Ev 'nan' 100prodcorr.txt > newtwo.txt
 1651  sort -k 2 -r newtwo.txt > sortednewone.txt
 1652  head sortednewone.txt
 1653  cd
 1654  ls
 1655  cd ~/a3/PRODUCTS
 1656  grep 0595356524 ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 9,14 > 0595356524.rvw.txt
 1657  nano 0595356524.rvw.txt
 1658  sed -i 's/<[^/]*\/>//g' 0595356524.rvw.txt
 1659  sed -i 's/\b[a-zA-Z]\{1,2\}\b//g' 0595356524.rvw.txt
 1660  sed -i -e 's/[\.,;]//g' -e 's/\band\b//g' -e 's/\bor\b//g' -e 's/\bif\b//g' -e 's/\bin\b//g' -e 's/\bit\b//g' 0595356524.rvw.txt
 1661  nano 0595356524.rvw.txt
 1662  awk -F '\t' '{if($1==1) print $2}' OFS=' ' 0595356524.rvw.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
 1663  awk -F '\t' '{if($1==0) print $2}' OFS=' ' 0595356524.rvw.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
 1664  cd
 1665  cd a3
 1666  rm -r CUSTOMERS
 1667  rm -r PRODUCTS
 1668  mv ~/a2/CUSTOMERS ~/a3/
 1669  cd
 1670  mv ~/a2/CUSTOMERS ~/a3/
 1671  ls
 1672  cd a2
 1673  ls
 1674  cd
 1675  ls
 1676  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort  
 1677  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort | uniq | wc -l
 1678  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort  
 1679  cut -f 2 amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -rn > topReviewID.txt
 1680  cd a2
 1681  ls
 1682  nano cust_n100.txt
 1683  nano cust100.txt
 1684  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done 
 1685  cd
 1686  ls
 1687  cp amazon_reviews_us_Books_v1_02.tsv
 1688  cp amazon_reviews_us_Books_v1_02.tsv a2
 1689  cd a2
 1690  ls
 1691  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done
 1692  mkdir CUSTOMERS
 1693  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done
 1694  pranav@f6linux3:~/a2$ for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done
 1695  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done
 1696  cut -d '        ' -f 2 amazon_reviews_us_Books_v1_02.tsv | sort | uniq -c | sort -k 1 | awk -F" " '$1 != 1 {print $2}' | tail -n 100 > customers.txt &
 1697  cd as
 1698  =cd a2
 1699  ls
 1700  cd a2
 1701  ls
 1702  cd customers
 1703  cd CUSTOMERS
 1704  ls
 1705  cd
 1706  cd a2
 1707  rm CUSTOMERS
 1708  rm -r CUSTOMERS
 1709  cd a2
 1710  ls
 1711  head cust100.txt
 1712  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done 
 1713  ls
 1714  mkdir CUSTOMERS
 1715  ls
 1716  cd CUSTOMERS
 1717  ls
 1718  rm 50122160.txt
 1719  cd ~/a2
 1720  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done
 1721  cd CUSTOMERS
 1722  ls
 1723  cd
 1724  cd a2
 1725  rm -r CUSTOMERS
 1726  ls
 1727  cd a2
 1728  ls
 1729  mkdir CUSTOMERS
 1730  for i in {1..100}; do numID=$(head -n $i cust100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > CUSTOMERS/$numID.txt; done 
 1731  head prod100.txt
 1732  cd CUSTOMERS
 1733  ls
 1734  nano 23488951.txt 
 1735  cd
 1736  cd a2
 1737  mkdir PRODUCTS
 1738  cd PRODUCTS
 1739  CD
 1740  cd
 1741  cd a2
 1742  for i in {1..100}; do numID=$(head -n $i prod100.txt | tail -1) && grep $numID amazon_reviews_us_Books_v1_02.tsv | cut -f 8,9 > PRODUCTS/$numID.txt; done 
 1743  cd
 1744  sudo apt install datamas
 1745  sudo apt install datamash
 1746  apt install datamash
 1747  sudo apt install datamash
 1748  cd a2
 1749  sudo apt install datamash
 1750  cd
 1751  wget http://ftp.gnu.org/gnu/datamash/datamash-1.3.tar.gz
 1752  tar -xzf datamash-1.3.tar.gz
 1753  cd datamash-1.3cd datamash-1.3
 1754  cd datamash-1.3
 1755  ./configure
 1756  make
 1757  make check
 1758  sudo make install
 1759  cd
 1760  cd a3
 1761  cd
 1762  cp ~/a2/CUSTOMERS ~/a3/
 1763  cp -r ~/a2/CUSTOMERS ~/a3/
 1764  cp -r ~/a2/PRODUCTS ~/a3/
 1765  script a3.txt
 1766  rm a3.txt
 1767  cp datamash-1.3 ~/a3/CUSTOMERS
 1768  cp -r datamash-1.3 ~/a3/CUSTOMERS
 1769  cp -r datamash-1.3 ~/a3/PRODUCTS
 1770  cd ~/a3/CUSTOMERS
 1771  cd a3
 1772  cd ~/a3/
 1773  script a3.txt
 1774  cd CUSTOMERS
 1775  for i in {1..200}; do filename=$(ls | head -n $i | tail -1) && filename2=$(echo $filename | cut -f 1 -d '.') && median=$(awk '{ sum+=$2; n++} END {print sum/n;}' $filename) &&  awk -v average="$median" '{if($2>average) print $1, "\t", 1; else print $1, "\t", 0}' $filename > $filename2.BINARY.txt;  done
 1776  ls
 1777  cd ~/a3/PRODUCTS
 1778  for i in {1..200}; do filename=$(ls | head -n $i | tail -1) && filename2=$(echo $filename | cut -f 1 -d '.') && median=$(awk '{ sum+=$2; n++} END {print sum/n;}' $filename) &&  awk -v average="$median" '{if($2>average) print $1, "\t", 1; else print $1, "\t", 0}' $filename > $filename2.BINARY.txt;  done
 1779  ls
 1780  cd datamash-1.3
 1781  for i in {1..100}; do filename=$(ls ~/a3/PRODUCTS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/PRODUCTS/$filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/PRODUCTS/prodcustcorr.txt; done
 1782  cd ~/a3/PRODUCTS
 1783  head 0060283262.BINARY.txt
 1784  cd ~/a3/CUSTOMERS
 1785  for i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/ $filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1786  ls
 1787  head 51380442.BINARY.txt 
 1788  head 1697838.BINARY.txt
 1789  head 51638342.BINARY.txt
 1790  cd datamash-1.3
 1791  for i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/ $filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1792  or i in {1..100}; do filename=$(ls ~/a2/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/  $filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >>/home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1793  for i in {1..100}; do filename=$(ls ~/a2/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/  $filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >>/home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1794  for i in {1..100}; do filename=$(ls ~/a2/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/ $filename)&& filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1795  cd
 1796  ~/a3/PRODUCTS
 1797  cd ~/a3/PRODUCTS
 1798  ls
 1799  head prodcustcorr.txt
 1800  cd ~/a3/CUSTOMERS
 1801  ls
 1802  for i in {1..100}; do filename=$(ls ~/a2/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/$filename)$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1803  for i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1804  ls
 1805  cd datamash-1.3
 1806  for i in {1..100}; do filename=$(ls ~/a3/CUSTOMERS/ | grep BINARY | head -n $i | tail -1) && correlation=$(./datamash -W ppearson 1:2 < /home/pranav/a3/CUSTOMERS/$filename) && filename2=$(echo $filename | cut -f 1 -d '.') && echo -e $filename2 '\t' $correlation >> /home/pranav/a3/CUSTOMERS/custcorr.txt; done
 1807  cd ~/a3/CUSTOMERS
 1808  ls
 1809  head custcorr.txt
 1810  sort -k 2 -r custcorr.txt > sortedcustcorr.txt
 1811  head sortedcustcorr.txt
 1812  grep -Ev 'nan'sortedcustcorr.txt > topcustcorr.txt
 1813  grep -Ev 'nan' sortedcustcorr.txt > topcustcorr.txt
 1814  head topcustcorr.txt
 1815  ls
 1816  head 49459388.BINARY.txt
 1817  nano 49459388.BINARY.txt
 1818  nano 12081595  0.87287156094397
 1819  nano 12081595.BINARY.txt
 1820  nano 53072811.BINARY.txt
 1821  cd ~/a3/PRODUCTS
 1822  ls
 1823  sort -k 2 -r prodcustcorr.txt > sortedprodcorr.txt
 1824  grep -Ev 'nan' sortedprodcorr.txt > topprodcorr.txt
 1825  head topprodcorr.txt
 1826  nano 0595356524.BINARY.txt
 1827  nano 1933060050.BINARY.txt
 1828  ~/a3/
 1829  ~/a3
 1830  cd ~/a3
 1831  grep 1933060050 ~/amazon_reviews_us_Books_v1_02.tsv | cut -f 9,14 > 1933060050.review.txt
 1832  sed -i 's/<[^/]*\/>//g' 1933060050.review.txt
 1833  sed -i 's/\b[a-zA-Z]\{1,2\}\b//g' 1933060050.review.txt
 1834  sed -i -e 's/[\.,;]//g' -e 's/\band\b//g' -e 's/\bor\b//g' -e 's/\bif\b//g' -e 's/\bin\b//g' -e 's/\bit\b//g' 1933060050.review.txt
 1835  awk -F '\t' '{if($1==1) print $2}' OFS=' ' 1933060050.review.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
 1836  awk -F '\t' '{if($1==0) print $2}' OFS=' ' 1933060050.review.txt | tr -s ' ' | tr '[:space:]' '[\n*]' | sort | uniq -c | sort -k1 -r | head -n 15
 1837  ls
 1838  vi a3.txt
 1839  vim a3.txt
 1840  nano a3.txt
 1841  vim a3.txt
 1842  nano a3.txt
 1843  cd a
 1844  cd a3
 1845  ls
 1846  git status
 1847  git add a3.txt
 1848  git status
 1849  git remote add origin https://github.com/pranav-chill/a3.git
 1850  git status
 1851  git add a3.txt
 1852  git status
 1853  git remote remove origin
 1854  git remote add origin https://github.com/pranav-chill/a3.git
 1855  git push -u origin master
 1856  git pull origin master
 1857  script ws8.txt
 1858  cd ws8
 1859  ls
 1860  nano unverified3.txt
 1861  cd ws8
 1862  ls
 1863  nano verified3.txt
 1864  script ws8.txt
 1865  rm unverified3.txt
 1866  head unverified2.txt
 1867  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1868  cd ws8
 1869  ls
 1870  rm unverified3.txt
 1871  script ws8.txt
 1872  grep -v '^$' verified3.txt | sort | uniq -c | sort -rn | awk '{print $2" "$1}' > verified_wc.txt
 1873  head -10 verified_wc.txt
 1874  grep -v '^$' unverified3.txt | sort | uniq -c | sort -rn | awk '{print $2" "$1}' > unverified_wc.txt
 1875  ls
 1876  head - 10 unverified_wc.txt
 1877  head -10 unverified_wc.txt
 1878  head -10 verified_wc.txt
 1879  head -10 unverified_wc.txt
 1880  nano ws8.txt
 1881  cd
 1882  rm -r ws8
 1883  ls
 1884  mkdir ws8
 1885  cd ws8
 1886  ls
 1887  script ws8.txt
 1888  awk -F'\t' '$12=="Y"' ~/amazon_reviews_us_Books_v1_02.tsv > verified.txt
 1889  awk -F'\t' '$12=="N"' ~/amazon_reviews_us_Books_v1_02.tsv > unverified.txt
 1890  head -n100 verified.txt | awk -F'\t' '{print$14}' >> verified.txt
 1891  head -n100 unverified.txt | awk -F'\t' '{print$14}' >> unverified.txt
 1892  tr " " "\n" < verified.txt >> verified2.txt
 1893  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' verified2.txt > verified3.txt
 1894  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1895  tr " " "\n" < unverified.txt >> unverified2.txt
 1896  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1897  ls
 1898  cd ws8
 1899  ls
 1900  nano ws8.txt
 1901  cd
 1902  rm -r ws8
 1903  ls
 1904  mkdir ws8
 1905  cd ws8
 1906  ls
 1907  script ws8
 1908  awk -F'\t' '$12=="Y"' ~/amazon_reviews_us_Books_v1_02.tsv > verified.txt
 1909  awk -F'\t' '$12=="N"' ~/amazon_reviews_us_Books_v1_02.tsv > verified.txt
 1910  cd ws8
 1911  ls
 1912  rm verified.txt
 1913  rm ws8
 1914  script ws8.txt
 1915  awk -F'\t' '$12=="Y"' ~/amazon_reviews_us_Books_v1_02.tsv > verified.txt
 1916  awk -F'\t' '$12=="N"' ~/amazon_reviews_us_Books_v1_02.tsv > unverified.txt
 1917  head -n100 verified.txt | awk -F'\t' '{print$14}' >> verified.txt
 1918  head -n100 unverified.txt | awk -F'\t' '{print$14}' >> unverified.txt
 1919  tr " " "\n" < verified.txt >> verified2.txt
 1920  head verified2.txt
 1921  tr '\n' ' ' < verified2.txt >> verified3.txt
 1922  head verified3.txt
 1923  cd ws8
 1924  ls
 1925  rm unverified.txt
 1926  rm verified.txt
 1927  rm verified2.txt
 1928  rm verified3.txt
 1929  rm ws8.txt
 1930  awk -F'\t' '$12=="Y"' ~/amazon_reviews_us_Books_v1_02.tsv> verified.txt
 1931  awk -F'\t' '$12=="N"' ~/amazon_reviews_us_Books_v1_02.tsv> unverified.txt
 1932  head -n100 verified.txt | awk -F'\t' '{print$14}' >> verified.txt
 1933  head -n100 unverified.txt | awk -F'\t' '{print$14}' >> unverified.txt
 1934  tr '\n' ' ' < verified.txt >> verified2.txt
 1935  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' verified2.txt > verified3.txt
 1936  tr ' ' '\n' < verified3.txt >> verified4.txt
 1937  head verified4.txt
 1938  nano verified4.txt
 1939  grep -v '^$' verified4.txt | sort | uniq -c | sort -rn | awk '{print $2" "$1}' > verified_wc.txt
 1940  tr '\n' ' ' < unverified.txt >> unverified2.txt
 1941  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1942  ls
 1943  rm unverified3.txt
 1944  head unverified3.txt
 1945  ls
 1946  rm verified3.txt
 1947  ed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1948  ls
 1949  rm unverified3.txt
 1950  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1951  ls
 1952  head unverified3.txt
 1953  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1954  rm unverified3.txt
 1955  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified2.txt > unverified3.txt
 1956  head verified_wc.txt
 1957  sed -i 's/\b[A-Za-z]\{1,2\}\b//g' univerified2.txt
 1958  sed -i 's/\b[A-Za-z]\{1,2\}\b//g' unverified2.txt
 1959  cd
 1960  cd ws8
 1961  sed -i 's/\b[A-Za-z]\{1,2\}\b//g' unverified2.txt
 1962  ls
 1963  cd
 1964  cd ws8
 1965  ls
 1966  cd
 1967  rm -r ws8
 1968  awk -F'\t' '$12=="Y"' ~/amazon_reviews_us_Books_v1_02.tsv> verified.txt
 1969  awk -F'\t' '$12=="N"' ~/amazon_reviews_us_Books_v1_02.tsv> unverified.txt
 1970  script ws8.txt
 1971  head -n100 verified.txt | awk -F'\t' '{print$14}' >> verified.txt
 1972  head -n100 unverified.txt | awk -F'\t' '{print$14}' >> unverified.txt
 1973  ls
 1974  sed 's/ /\n/g' verified.txt > verified2.txt
 1975  sed -i 's/[.,]//g' verified2.txt > verified3.txt
 1976  sed -i '/^[[:space:]]*$/d' verified3.txt > verified4.txt
 1977  head verified4.txt
 1978  nano verified4.txt
 1979  head verified3.txt
 1980  head verified2.txt
 1981  ls
 1982  rm verified2.txt
 1983  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' verified.txt > verified2.txt
 1984  head verified2.txt
 1985  tr ' ' '\n' < verified2.txt >> verified3.txt
 1986  head verified3.txt
 1987  sort verified3.txt | sort | uniq -c | sort -rn | awk '{print $2" "$1}' > verified_wc.txt
 1988  ls
 1989  sed 's/[.,;!?]/ /g; s/ and / /g; s/ or / /g; s/ if / /g; s/ in / /g; s/ it / /g; s/<[^>]\+>/ /g; s/[ ][a-zA-Z0-9]\{1,2\}[ ]/ /g' unverified.txt > unverified2.txt
 1990  head unverified2.txt
 1991  tr ' ' '\n' < unverified2.txt >> unverified3.txt
 1992  sort unverified3.txt | sort | uniq -c | sort -rn | awk '{print $2" "$1}' > unverified_wc.txt
 1993  head unverified_wc.txt
 1994  head verified_wc.txt
 1995  sort unverified3.txt | uniq -c | sort -rn > unverified_wc.txt
 1996  cd ws8
 1997  ls
 1998  nano ws8.txt
 1999  history
 2000  cd ws8
 2001  history > cmds.log
